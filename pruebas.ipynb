{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISIS SOBRE METODOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/david/OneDrive - Universidade de Santiago de Compostela/TFG DAVID MACIAS/Contenidos/Workspace/env/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creación del conjunto de datos de entreno y de test\n",
    "train_dataset = pd.read_csv((\"./datasets/method.csv\"), index_col = 'LongName')\n",
    "train_dataset, test_dataset = train_test_split(train_dataset, test_size=0.2)\n",
    "\n",
    "display(train_dataset.head(3))\n",
    "display(test_dataset.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nombre de la columna donde se encuentra el resultado del fichero\n",
    "salida = 'Number of Bugs'\n",
    "# Columnas del dataset \n",
    "features = [\"CC\",\"CCL\",\"CCO\",\"CI\",\"CLC\",\"CLLC\",\"LDC\",\"LLDC\",\"HCPL\",\"HDIF\",\"HEFF\",\"HNDB\",\"HPL\",\"HPV\",\"HTRP\",\"HVOL\",\"MI\",\"MIMS\",\"MISEI\",\"MISM\",\"McCC\",\"NL\",\"NLE\",\"NII\",\"NOI\",\"CD\",\"CLOC\",\"DLOC\",\"TCD\",\"TCLOC\",\"LLOC\",\"LOC\",\"NOS\",\"NUMPAR\",\"TLLOC\",\"TLOC\",\"TNOS\",\"WarningBlocker\",\"WarningCritical\",\"WarningInfo\",\"WarningMajor\",\"WarningMinor\",\"Android Rules\",\"Basic Rules\",\"Brace Rules\",\"Clone Implementation Rules\",\"Code Size Rules\",\"Comment Rules\",\"Controversial Rules\",\"Coupling Rules\",\"Design Rules\",\"Empty Code Rules\",\"Finalizer Rules\",\"Import Statement Rules\",\"J2EE Rules\",\"JUnit Rules\",\"Jakarta Commons Logging Rules\",\"Java Logging Rules\",\"JavaBean Rules\",\"MigratingToJUnit4 Rules\",\"Migration Rules\",\"Migration13 Rules\",\"Migration14 Rules\",\"Migration15 Rules\",\"Naming Rules\",\"Optimization Rules\",\"Security Code Guideline Rules\",\"Strict Exception Rules\",\"String and StringBuffer Rules\",\"Type Resolution Rules\",\"Unnecessary and Unused Code Rules\",\"Vulnerability Rules\"]\n",
    "\n",
    "# TODO En la columna de outcome se indica la cantidad de bugs que hay en ese metodo, hay que gestionar este outcome para que consiga interpretar un valor no binario (0, 1) si no tambien la cantidad 0-6 \n",
    "# Creacion de una nueva columna con valores (0, 1)\n",
    "# Se indica que la feature outcome es una variable categórica, que toma valores en un intervalo limitado\n",
    "train_dataset[salida] = pd.Categorical(train_dataset[salida])\n",
    "display(train_dataset[salida])\n",
    "# Convertimos las variables en códigos en función de la categoría \n",
    "train_dataset[salida] = train_dataset[salida].cat.codes\n",
    "display(train_dataset[salida])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacemos la misma conversión con los datos del conjunto de test\n",
    "test_dataset[salida] = pd.Categorical(test_dataset[salida])\n",
    "test_dataset[salida] = test_dataset[salida].cat.codes\n",
    "\n",
    "# Se construyen los dataset con las features, separándolos de la salida\n",
    "X_train = train_dataset.loc[:, features]\n",
    "X_test = test_dataset.loc[:, features]\n",
    "# display(X_train)\n",
    "\n",
    "# Se construye el dataset de salidas \n",
    "y_train = train_dataset.loc[:, salida]\n",
    "y_test = test_dataset.loc[:, salida]\n",
    "# display(Y_train)\n",
    "\n",
    "class_labels = ['Limpio', 'Buggy1', 'Buggy2', 'Buggy3', 'Buggy4', 'Buggy5', 'Buggy6']\n",
    "\n",
    "X_train.columns = features\n",
    "X_test.columns = features \n",
    "\n",
    "training_data = pd.concat([X_train, y_train], axis = 1)\n",
    "testing_data = pd.concat([X_test, y_test], axis = 1)\n",
    "display(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construccion del modelo\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=0)\n",
    "# Se entrena el modelo\n",
    "rf_model.fit(X_train, y_train)  \n",
    "# print(rf_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de Lime \n",
    "import lime \n",
    "import lime.lime_tabular\n",
    "\n",
    "# Explicamos el primer metodo del conjunto de test\n",
    "metodo_explicado = y_test.keys()[0]\n",
    "metodo_a_explicar = metodo_explicado\n",
    "\n",
    "# print(f'Explaining {file_to_be_explained} with Lime')\n",
    "\n",
    "\"\"\" \n",
    "Construir el modelo explicador de Lime\n",
    "\ttraining_data: conjunto de entrenamiento con las features\n",
    "\tmode: clasificacion o regresion \n",
    "\ttraining_labels: conjunto de entrenamiento con los resultados de las entradas \n",
    "\tfeature_names: lista de nombres de las features analizadas \n",
    "\tclass_names: lista del nombre de las clases ?????\n",
    "\tdiscretize_continuous: si es True, todas las variables no categóricas seran discretizadas en quartiles.\n",
    "\"\"\"\n",
    "our_lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "\ttraining_data = X_train.values, \n",
    "\tmode = 'classification', \n",
    "\ttraining_labels = y_train,\n",
    "\tfeature_names = features, \n",
    "\tclass_names = class_labels, \n",
    "\tdiscretize_continuous = True\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Usar el modelo explicador con la función de predicción para generar la explicación sobre la predicción\n",
    "\tdata_row: fila del conjunto de datos que queremos explicar \n",
    "\tpredict_fn: funcion de prediccion \n",
    "\tnum_features: máximo numero de features a las que dar explicación\n",
    "\ttop_labels: ignora las labels y produce explicaciones para las K labels con las mejores predicciones de probabilidad donde K es el parametro\n",
    "\"\"\"\n",
    "lime_local_explanation_of_an_instance = our_lime_explainer.explain_instance(\n",
    "\tdata_row = X_test.loc[metodo_explicado, :],\n",
    "\tpredict_fn = rf_model.predict_proba,\n",
    "\tnum_features = 5,\n",
    "\ttop_labels = 1\n",
    ")\n",
    "\n",
    "# Visualización de las explicaciones \n",
    "lime_local_explanation_of_an_instance.show_in_notebook()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa4d2b9842c35b17c646ef73e353153bd1c14def619b4fc7a9eef80f94a7b55b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
